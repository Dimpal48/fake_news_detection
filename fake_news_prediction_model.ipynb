{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dimpi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dimpi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load and explore the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Government Announces New Education Reforms</td>\n",
       "      <td>The education ministry has proposed reforms to...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Economy Shows Signs of Recovery</td>\n",
       "      <td>The new study conducted by international resea...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aliens Land in Central Park</td>\n",
       "      <td>Sources claim that extraterrestrial beings wer...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aliens Land in Central Park</td>\n",
       "      <td>The celebrity stated that secret documents rev...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Study Reveals Health Benefits of Walking</td>\n",
       "      <td>The education ministry has proposed reforms to...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title  \\\n",
       "0    Government Announces New Education Reforms   \n",
       "1               Economy Shows Signs of Recovery   \n",
       "2                   Aliens Land in Central Park   \n",
       "3                   Aliens Land in Central Park   \n",
       "4  New Study Reveals Health Benefits of Walking   \n",
       "\n",
       "                                                text label  \n",
       "0  The education ministry has proposed reforms to...  real  \n",
       "1  The new study conducted by international resea...  real  \n",
       "2  Sources claim that extraterrestrial beings wer...  fake  \n",
       "3  The celebrity stated that secret documents rev...  fake  \n",
       "4  The education ministry has proposed reforms to...  real  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('15_fake_news_detection.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    0\n",
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "real    532\n",
       "fake    468\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2 : Preprocess the Datsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df, use_stemming=False, use_lemmatization=True):\n",
    "    \"\"\"\n",
    "    Preprocesses the 'title' and 'text' columns of a given DataFrame.\n",
    "    \n",
    "    Steps:\n",
    "    1. Convert text to lowercase\n",
    "    2. Remove punctuation & special characters\n",
    "    3. Remove stopwords\n",
    "    4. Apply stemming or lemmatization\n",
    "    5. Convert text into numerical form using TF-IDF\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing 'title' and 'text' columns.\n",
    "    - use_stemming: Boolean flag to apply stemming (default: False)\n",
    "    - use_lemmatization: Boolean flag to apply lemmatization (default: True)\n",
    "\n",
    "    Returns:\n",
    "    - Processed DataFrame with TF-IDF features added.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Convert text to lowercase\n",
    "    df['title'] = df['title'].fillna('').astype(str).str.lower()\n",
    "    df['text'] = df['text'].fillna('').astype(str).str.lower()\n",
    "\n",
    "    # 2. Remove Punctuation & Special Characters\n",
    "    df['title'] = df['title'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
    "\n",
    "    # 3. Remove Stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df['title'] = df['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "    df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "\n",
    "    # 4. Apply Stemming or Lemmatization\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    if use_stemming:\n",
    "        df['title'] = df['title'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "        df['text'] = df['text'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "\n",
    "    if use_lemmatization:\n",
    "        df['title'] = df['title'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "        df['text'] = df['text'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "\n",
    "    # 5. Convert Text to TF-IDF\n",
    "    vectorizer_title = TfidfVectorizer()\n",
    "    vectorizer_text = TfidfVectorizer()\n",
    "\n",
    "    title_tfidf_matrix = vectorizer_title.fit_transform(df['title'])\n",
    "    text_tfidf_matrix = vectorizer_text.fit_transform(df['text'])\n",
    "\n",
    "    # Convert sparse matrix to DataFrame\n",
    "    title_tfidf_df = pd.DataFrame(title_tfidf_matrix.toarray(), columns=vectorizer_title.get_feature_names_out())\n",
    "    text_tfidf_df = pd.DataFrame(text_tfidf_matrix.toarray(), columns=vectorizer_text.get_feature_names_out())\n",
    "\n",
    "    # Merge with the original DataFrame\n",
    "    df = pd.concat([df, title_tfidf_df, text_tfidf_df], axis=1)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>aging</th>\n",
       "      <th>alien</th>\n",
       "      <th>announces</th>\n",
       "      <th>benefit</th>\n",
       "      <th>celebrity</th>\n",
       "      <th>central</th>\n",
       "      <th>cure</th>\n",
       "      <th>...</th>\n",
       "      <th>source</th>\n",
       "      <th>spaceship</th>\n",
       "      <th>stated</th>\n",
       "      <th>steadily</th>\n",
       "      <th>stepping</th>\n",
       "      <th>study</th>\n",
       "      <th>tea</th>\n",
       "      <th>two</th>\n",
       "      <th>village</th>\n",
       "      <th>walking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>government announces new education reform</td>\n",
       "      <td>education ministry proposed reform modernize c...</td>\n",
       "      <td>real</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>economy show sign recovery</td>\n",
       "      <td>new study conducted international researcher s...</td>\n",
       "      <td>real</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alien land central park</td>\n",
       "      <td>source claim extraterrestrial being seen stepp...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389794</td>\n",
       "      <td>0.389794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.389794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alien land central park</td>\n",
       "      <td>celebrity stated secret document reveal shocki...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new study reveals health benefit walking</td>\n",
       "      <td>education ministry proposed reform modernize c...</td>\n",
       "      <td>real</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.443386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title  \\\n",
       "0  government announces new education reform   \n",
       "1                 economy show sign recovery   \n",
       "2                    alien land central park   \n",
       "3                    alien land central park   \n",
       "4   new study reveals health benefit walking   \n",
       "\n",
       "                                                text label  aging  alien  \\\n",
       "0  education ministry proposed reform modernize c...  real    0.0    0.0   \n",
       "1  new study conducted international researcher s...  real    0.0    0.0   \n",
       "2  source claim extraterrestrial being seen stepp...  fake    0.0    0.5   \n",
       "3  celebrity stated secret document reveal shocki...  fake    0.0    0.5   \n",
       "4  education ministry proposed reform modernize c...  real    0.0    0.0   \n",
       "\n",
       "   announces   benefit  celebrity  central  cure  ...    source  spaceship  \\\n",
       "0   0.488463  0.000000        0.0      0.0   0.0  ...  0.000000   0.000000   \n",
       "1   0.000000  0.000000        0.0      0.0   0.0  ...  0.000000   0.000000   \n",
       "2   0.000000  0.000000        0.0      0.5   0.0  ...  0.389794   0.389794   \n",
       "3   0.000000  0.000000        0.0      0.5   0.0  ...  0.000000   0.000000   \n",
       "4   0.000000  0.443386        0.0      0.0   0.0  ...  0.000000   0.000000   \n",
       "\n",
       "     stated  steadily  stepping     study  tea  two  village   walking  \n",
       "0  0.000000       0.0  0.000000  0.000000  0.0  0.0      0.0  0.000000  \n",
       "1  0.000000       0.0  0.000000  0.323667  0.0  0.0      0.0  0.323667  \n",
       "2  0.000000       0.0  0.389794  0.000000  0.0  0.0      0.0  0.000000  \n",
       "3  0.362895       0.0  0.000000  0.000000  0.0  0.0      0.0  0.000000  \n",
       "4  0.000000       0.0  0.000000  0.000000  0.0  0.0      0.0  0.000000  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= preprocess_text(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1.coverting text to lowercase\n",
    "# df['title']=df['title'].str.lower()\n",
    "# df['text']=df['text'].str.lower()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  2.Remove Punctuation & Special Characters\n",
    "# df['title'] = df['title'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
    "# df['text'] = df['text'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3. Remove Stopwords\n",
    "\n",
    "# #Load English Stopwords\n",
    "# stop_words=set(stopwords.words('english'))\n",
    "# df['title']=df['title'].apply(lambda x:x.split())\n",
    "# df['text']=df['text'].apply(lambda x:x.split())\n",
    "# df['title']=df['title'].apply(lambda words: [word for word in words if word.lower() not in stop_words])\n",
    "# df['text']=df['text'].apply(lambda words:[word for word in words if word.lower() not in stop_words] )\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 4. Perform Stemming or Lemmatization\n",
    "# #Stemming\n",
    "# stemmer=PorterStemmer()\n",
    "# df['title']=df['title'].apply(lambda words:[stemmer.stem(word) for word in words])\n",
    "# df['text']=df['text'].apply(lambda words:[stemmer.stem(word) for word in words])\n",
    "\n",
    "# #Lemmatization\n",
    "# lemmatizer=WordNetLemmatizer()\n",
    "# df['title']=df['title'].apply(lambda words:[lemmatizer.lemmatize(word) for word in words])\n",
    "# df['title']=df['text'].apply(lambda words:[lemmatizer.lemmatize(word) for word in words])\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# corpus = [\"Fake news is spreading\", \"Real news provides facts\"]\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# print(vectorizer.get_feature_names_out())  # Vocabulary\n",
    "# print(X.toarray())  # TF-IDF matrix\n",
    "# ['fake' 'facts' 'is' 'news' 'provides' 'real' 'spreading']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5. Tokenization\n",
    "# df['title']=df['title'].apply(lambda x:word_tokenize(str(x)))\n",
    "# df['text']=df['text'].apply(lambda x: word_tokenize(str(x)))\n",
    "# df.head()\n",
    "# # #6 Convert text into Numerical from --> using TF-IDF(term frequency-Inverse Document frequency)\n",
    "# vectorizer_title = TfidfVectorizer()\n",
    "# vectorizer_text = TfidfVectorizer()\n",
    "\n",
    "# # Ensure text data is clean\n",
    "# df['title'] = df['title'].fillna('').astype(str)\n",
    "# df['text'] = df['text'].fillna('').astype(str)\n",
    "\n",
    "# # Apply TF-IDF separately\n",
    "# title_tfidf_matrix = vectorizer_title.fit_transform(df['title'])\n",
    "# text_tfidf_matrix = vectorizer_text.fit_transform(df['text'])\n",
    "\n",
    "# # Convert to DataFrame\n",
    "# title_tfidf_df = pd.DataFrame(title_tfidf_matrix.toarray(), columns=vectorizer_title.get_feature_names_out())\n",
    "# text_tfidf_df = pd.DataFrame(text_tfidf_matrix.toarray(), columns=vectorizer_text.get_feature_names_out())\n",
    "\n",
    "# # Merge with original DataFrame\n",
    "# df = pd.concat([df, title_tfidf_df, text_tfidf_df], axis=1)\n",
    "\n",
    "# # Display transformed data\n",
    "# df.head()\n",
    "# # df['title']=vectorizer.fit_transform(df['title'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Split Data into training and testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.  Define Feature(X) and target (y)\n",
    "X=df.drop(columns=['label'])\n",
    "Y=df['label']\n",
    "#2. Perform Train-Test Split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42,stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train the SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Optimize the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Deploy the Model (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
